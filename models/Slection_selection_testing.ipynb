{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b4c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pydicom\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# --------------------------- SEED ---------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ---------------------- DEVICE ------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "# ------------------------- PARAMS ---------------------------\n",
    "NUM_SLICES = 18\n",
    "IMG_SIZE   = 256\n",
    "\n",
    "LEVELS = [\"L1-L2\",\"L2-L3\",\"L3-L4\",\"L4-L5\",\"L5-S1\"]\n",
    "SIDES  = [\"left\",\"right\"]\n",
    "TARGET_KEYS = [f\"{l}_{s}\" for l in LEVELS for s in SIDES]  # 10 outputs\n",
    "\n",
    "BATCH_SIZE  = 8\n",
    "NUM_WORKERS = 0  # Windows safe\n",
    "\n",
    "# ------------------------- PATHS ----------------------------\n",
    "images_root = r\"D:\\Submitted Matrial (conference&journal)\\Sagittal Data Artical\\V0.47 Dataset analysis\\dataspitting\\split_dataset\\images\"\n",
    "dicom_root  = os.path.join(images_root, \"test\")  # <--- test DICOM folders\n",
    "label_root  = r\"D:\\Submitted Matrial (conference&journal)\\Sagittal Data Artical\\V0.47 Dataset analysis\\dataspitting\\split_dataset\\label\\test\"\n",
    "\n",
    "model_path  = r\"D:\\Submitted Matrial (conference&journal)\\Sagittal Data Artical\\V0.47 Dataset analysis\\dataspitting\\best_model_convnext3d_regression.pth\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#                   PREPROCESSING\n",
    "# ============================================================\n",
    "\n",
    "def extract_foreground(img, threshold=10):\n",
    "    mask = img > threshold\n",
    "    if not np.any(mask):\n",
    "        return img\n",
    "    coords = np.column_stack(np.where(mask))\n",
    "    y_min, x_min = coords.min(axis=0)\n",
    "    y_max, x_max = coords.max(axis=0)\n",
    "    return img[y_min:y_max+1, x_min:x_max+1]\n",
    "\n",
    "def extract_labels(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    label = []\n",
    "    mask  = []\n",
    "    for key in TARGET_KEYS:\n",
    "        lvl, side = key.split(\"_\")\n",
    "        coord = data.get(lvl, {}).get(side)\n",
    "        if coord is None:\n",
    "            label.append(0.0)\n",
    "            mask.append(0.0)\n",
    "        else:\n",
    "            z = coord[2]  # normalized [0..1]\n",
    "            z_index = int(round(z * NUM_SLICES))\n",
    "            z_index = max(0, min(NUM_SLICES - 1, z_index))\n",
    "            label.append(float(z_index))\n",
    "            mask.append(1.0)\n",
    "\n",
    "    return np.array(label, dtype=np.float32), np.array(mask, dtype=np.float32)\n",
    "\n",
    "def load_and_preprocess_volume(dicom_dir):\n",
    "    files = [os.path.join(dicom_dir, f) for f in os.listdir(dicom_dir) if f.endswith(\".dcm\")]\n",
    "    if len(files) == 0:\n",
    "        raise RuntimeError(f\"No DICOM files in {dicom_dir}\")\n",
    "\n",
    "    def sort_key(p):\n",
    "        try:\n",
    "            return int(pydicom.dcmread(p, stop_before_pixels=True).InstanceNumber)\n",
    "        except Exception:\n",
    "            return p\n",
    "\n",
    "    files = sorted(files, key=sort_key)\n",
    "\n",
    "    # enforce NUM_SLICES\n",
    "    if len(files) > NUM_SLICES:\n",
    "        s = (len(files) - NUM_SLICES) // 2\n",
    "        files = files[s:s + NUM_SLICES]\n",
    "    elif len(files) < NUM_SLICES:\n",
    "        files = files + [files[-1]] * (NUM_SLICES - len(files))\n",
    "\n",
    "    vol = []\n",
    "    for p in files:\n",
    "        ds = pydicom.dcmread(p)\n",
    "        img = ds.pixel_array.astype(np.float32)\n",
    "\n",
    "        img = extract_foreground(img)\n",
    "        img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "        vol.append(img)\n",
    "\n",
    "    vol = np.stack(vol).astype(np.float32)  # (D,H,W)\n",
    "    if vol.shape != (NUM_SLICES, IMG_SIZE, IMG_SIZE):\n",
    "        raise RuntimeError(f\"Bad volume shape {vol.shape} in {dicom_dir}\")\n",
    "\n",
    "    return vol\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#                   DATASET / LOADER\n",
    "# ============================================================\n",
    "\n",
    "class LumbarDataset(Dataset):\n",
    "    def __init__(self, ids):\n",
    "        self.ids = ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pid = self.ids[idx]\n",
    "        vol_path   = os.path.join(dicom_root, pid)\n",
    "        label_path = os.path.join(label_root, f\"{pid}.json\")\n",
    "\n",
    "        vol = load_and_preprocess_volume(vol_path)\n",
    "        y, m = extract_labels(label_path)\n",
    "\n",
    "        vol = torch.from_numpy(vol).unsqueeze(0).float()  # (1,D,H,W)\n",
    "        y   = torch.from_numpy(y).float()\n",
    "        m   = torch.from_numpy(m).float()\n",
    "        return vol, y, m\n",
    "\n",
    "\n",
    "# Collect only valid patients that have json labels\n",
    "patient_ids = []\n",
    "for pid in os.listdir(dicom_root):\n",
    "    vol_path   = os.path.join(dicom_root, pid)\n",
    "    label_path = os.path.join(label_root, f\"{pid}.json\")\n",
    "    if os.path.isdir(vol_path) and os.path.exists(label_path):\n",
    "        patient_ids.append(pid)\n",
    "\n",
    "print(\"Total test samples:\", len(patient_ids))\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    LumbarDataset(patient_ids),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#                   MODEL\n",
    "# ============================================================\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super().__init__()\n",
    "        self.dw  = nn.Conv3d(c, c, kernel_size=(3,7,7), padding=(1,3,3), groups=c, bias=False)\n",
    "        self.gn  = nn.GroupNorm(1, c)\n",
    "        self.pw1 = nn.Conv3d(c, 4*c, kernel_size=1, bias=False)\n",
    "        self.act = nn.GELU()\n",
    "        self.pw2 = nn.Conv3d(4*c, c, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pw2(self.act(self.pw1(self.gn(self.dw(x)))))\n",
    "\n",
    "\n",
    "class ConvNext3D(nn.Module):\n",
    "    def __init__(self, n_outputs=10):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Conv3d(1, 64, kernel_size=(1,4,4), stride=(1,4,4), bias=False)\n",
    "        self.b1   = Block(64)\n",
    "\n",
    "        self.d1   = nn.Conv3d(64, 128, kernel_size=2, stride=2, bias=False)\n",
    "        self.b2   = Block(128)\n",
    "\n",
    "        self.d2   = nn.Conv3d(128, 256, kernel_size=2, stride=2, bias=False)\n",
    "        self.b3   = Block(256)\n",
    "\n",
    "        self.d3   = nn.Conv3d(256, 512, kernel_size=2, stride=2, bias=False)\n",
    "        self.b4   = Block(512)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc   = nn.Linear(512, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.b1(self.stem(x))\n",
    "        x = self.b2(self.d1(x))\n",
    "        x = self.b3(self.d2(x))\n",
    "        x = self.b4(self.d3(x))\n",
    "        x = self.pool(x).flatten(1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ConvNext3D(n_outputs=10).to(device).to(memory_format=torch.channels_last_3d)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_preds, all_targets, all_masks = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for vol, target, mask in test_loader:\n",
    "        vol    = vol.to(device, non_blocking=True).to(memory_format=torch.channels_last_3d)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "        mask   = mask.to(device, non_blocking=True)\n",
    "\n",
    "        with autocast(enabled=(device.type == \"cuda\")):\n",
    "            pred = model(vol)\n",
    "\n",
    "        all_preds.append(pred.detach().cpu())\n",
    "        all_targets.append(target.detach().cpu())\n",
    "        all_masks.append(mask.detach().cpu())\n",
    "\n",
    "all_preds   = torch.cat(all_preds, dim=0)\n",
    "all_targets = torch.cat(all_targets, dim=0)\n",
    "all_masks   = torch.cat(all_masks, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Y_pr = all_preds.int()\n",
    "# medail point is 6 \n",
    "true_prediction  =  0 \n",
    "false_prediction = 0\n",
    "for i,x,z in zip (Y_pr,all_targets , all_masks):\n",
    "    left =[] \n",
    "    right = []\n",
    "    for j in range(len(i)):\n",
    "        if j%2 == 0:\n",
    "            left.append(i[j])\n",
    "        else:\n",
    "            right.append(i[j])\n",
    "   \n",
    "    # # ---------------------- Prediction Analysis ----------------------\n",
    "    most_common_left = np.array(Counter(left).most_common(1)[0][0])\n",
    "    most_common_right = np.array(Counter(right).most_common(1)[0][0])\n",
    "\n",
    "\n",
    "\n",
    "    for iter in range(len(x)):\n",
    "        if z[iter] == 1:\n",
    "            if x[iter] == 0:\n",
    "               continue\n",
    "            # here for the left side\n",
    "            elif iter % 2 == 0:\n",
    "                if x[iter] == most_common_left  or x[iter]== most_common_left +1 or x[iter] == most_common_left -1:\n",
    "                    true_prediction += 1\n",
    "                else:\n",
    "                    false_prediction += 1\n",
    "            # here for the right side\n",
    "            else:\n",
    "                if x[iter] == most_common_right or x[iter] == most_common_right + 1 or x[iter] == most_common_right - 1:\n",
    "                    true_prediction += 1\n",
    "                else:\n",
    "                    false_prediction += 1\n",
    "          \n",
    "           \n",
    "\n",
    "\n",
    "  \n",
    "accuracy_percent = true_prediction / (true_prediction + false_prediction) * 100\n",
    "print(f\"Accuracy of the model: {accuracy_percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014a60cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------------------- Most Common Left/Right Accuracy (±1 tolerance) ----------------------\n",
    "Y_pr = all_preds.int()\n",
    "true_prediction = 0\n",
    "false_prediction = 0\n",
    "\n",
    "for i, x, z in zip(Y_pr, all_targets, all_masks):\n",
    "    left = [i[j].item() for j in range(len(i)) if j % 2 == 0]\n",
    "    right = [i[j].item() for j in range(len(i)) if j % 2 == 1]\n",
    "\n",
    "    most_common_left = Counter(left).most_common(1)[0][0]\n",
    "    most_common_right = Counter(right).most_common(1)[0][0]\n",
    "\n",
    "    for idx in range(len(x)):\n",
    "        if z[idx] == 1:\n",
    "            if x[idx] == 0:\n",
    "                continue\n",
    "            # Left side\n",
    "            if idx % 2 == 0:\n",
    "                if x[idx] in [most_common_left, most_common_left + 1, most_common_left - 1]:\n",
    "                    true_prediction += 1\n",
    "                else:\n",
    "                    false_prediction += 1\n",
    "            # Right side\n",
    "            else:\n",
    "                if x[idx] in [most_common_right, most_common_right + 1, most_common_right - 1]:\n",
    "                    true_prediction += 1\n",
    "                else:\n",
    "                    false_prediction += 1\n",
    "\n",
    "if (true_prediction + false_prediction) > 0:\n",
    "    accuracy_percent = true_prediction / (true_prediction + false_prediction) * 100\n",
    "    print(f\"Most common left/right accuracy (±1): {accuracy_percent:.2f}%\")\n",
    "else:\n",
    "    print(\"No valid predictions for most common left/right accuracy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db63dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (true_prediction + false_prediction) > 0:\n",
    "    accuracy_percent = true_prediction / (true_prediction + false_prediction) * 100\n",
    "    precision_percent = true_prediction / (true_prediction + false_prediction) * 100  # For this context, precision = accuracy\n",
    "    print(f\"Most common left/right accuracy (±1): {accuracy_percent:.2f}%\")\n",
    "    print(f\"Precision (±1): {precision_percent:.2f}%\")\n",
    "else:\n",
    "    print(\"No valid predictions for most common left/right accuracy.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
