{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f10d519a",
   "metadata": {},
   "source": [
    "### training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab12113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- 1. Imports ----------------------\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from fastai.vision.all import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "\n",
    "# ---------------------- 2. Configuration ----------------------\n",
    "BATCH_SIZE = 16  \n",
    "IMG_SIZE = 224\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "dataset_root = r\"D:\\Submitted Matrial (conference&journal)\\Sagittal Data Artical\\V0.47 Dataset analysis\\dataspitting\\Cropped_ROIs_V0.47_Split\\train_by_class\"\n",
    "\n",
    "# Auto-detect Device\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Running on device: {device}\")\n",
    "\n",
    "# ---------------------- 3. Transforms ----------------------\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=30, p=0.7),\n",
    "    A.RandomBrightnessContrast(p=0.7),\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# ---------------------- 4. Dataset Classes ----------------------\n",
    "class ImageFolderDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.samples = []\n",
    "        self.classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        for label_str in self.classes:\n",
    "            label_dir = os.path.join(root_dir, label_str)\n",
    "            label = self.class_to_idx[label_str]\n",
    "            for fname in os.listdir(label_dir):\n",
    "                if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                    self.samples.append((os.path.join(label_dir, fname), label))\n",
    "                    \n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None: return np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8), label\n",
    "        img = cv2.equalizeHist(cv2.resize(img, (IMG_SIZE, IMG_SIZE)))\n",
    "        img = np.stack([img]*3, axis=-1)\n",
    "        return img, label\n",
    "\n",
    "class AlbumentationsDataset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.subset)\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.subset[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, label\n",
    "\n",
    "# ---------------------- 5. Setup Data ----------------------\n",
    "full_ds_raw = ImageFolderDataset(dataset_root)\n",
    "train_idx, val_idx = train_test_split(list(range(len(full_ds_raw))), test_size=0.2, random_state=42, stratify=[s[1] for s in full_ds_raw.samples])\n",
    "\n",
    "train_dataset = AlbumentationsDataset(torch.utils.data.Subset(full_ds_raw, train_idx), transform=train_transform)\n",
    "val_dataset = AlbumentationsDataset(torch.utils.data.Subset(full_ds_raw, val_idx), transform=val_transform)\n",
    "\n",
    "dls = DataLoaders.from_dsets(\n",
    "    train_dataset, val_dataset,\n",
    "    bs=BATCH_SIZE,\n",
    "    num_workers=0, \n",
    "    pin_memory=False,\n",
    "    device=device \n",
    ")\n",
    "\n",
    "# ---------------------- 6. Handle Class Imbalance (NEW) ----------------------\n",
    "# 1. Count samples in each class\n",
    "all_labels = [label for _, label in full_ds_raw.samples]\n",
    "counts = Counter(all_labels)\n",
    "print(f\"Class Counts: {dict(counts)}\")\n",
    "\n",
    "# 2. Calculate Inverse Weights: (Total / Class_Count)\n",
    "# Rare classes get HIGH weights, Common classes get LOW weights\n",
    "weights = []\n",
    "for i in range(len(full_ds_raw.classes)):\n",
    "    count = counts.get(i, 0)\n",
    "    if count > 0:\n",
    "        weights.append(1.0 / count)\n",
    "    else:\n",
    "        weights.append(1.0) # Prevent division by zero\n",
    "\n",
    "# 3. Normalize weights so they sum to the number of classes (optional but standard)\n",
    "weights = torch.tensor(weights, dtype=torch.float)\n",
    "weights = weights / weights.sum() * len(full_ds_raw.classes)\n",
    "weights = weights.to(device)\n",
    "\n",
    "print(f\"Calculated Class Weights: {weights}\")\n",
    "\n",
    "# ---------------------- 7. Model Setup ----------------------\n",
    "print(\"Loading Model...\")\n",
    "model = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_patch16_224', pretrained=True)\n",
    "model.head = nn.Sequential(nn.Dropout(0.25), nn.Linear(192, len(full_ds_raw.classes)))\n",
    "model = model.to(device)\n",
    "\n",
    "# Apply the WEIGHTS to the Loss Function here\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(weight=weights), metrics=accuracy)\n",
    "\n",
    "# ---------------------- 8. Training ----------------------\n",
    "print(\"Starting Training...\")\n",
    "with learn.no_bar():\n",
    "    learn.fit_one_cycle(EPOCHS, lr_max=LEARNING_RATE)\n",
    "\n",
    "# ---------------------- 9. Evaluation ----------------------\n",
    "print(\"Saving Model...\")\n",
    "save_path = os.path.join(dataset_root, 'deit_balanced.pth')\n",
    "torch.save(learn.model.state_dict(), save_path) # Save pure state dict for safety\n",
    "\n",
    "print(\"\\nEvaluation...\")\n",
    "learn.model.eval()\n",
    "preds, targs = learn.get_preds()\n",
    "preds_classes = preds.argmax(dim=1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(targs, preds_classes, target_names=full_ds_raw.classes))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(targs, preds_classes)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=full_ds_raw.classes)\n",
    "disp.plot(cmap='Blues', values_format='d', ax=ax)\n",
    "plt.title(\"Confusion Matrix (Balanced Training)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a78174",
   "metadata": {},
   "source": [
    "#### testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- 1. Imports ----------------------\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from fastai.vision.all import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "\n",
    "# ---------------------- 2. Configuration ----------------------\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 4  # Ensure this matches your training (0, 1, 2, 3)\n",
    "\n",
    "# Path to your TEST folder\n",
    "test_dataset_root = r\"D:\\Submitted Matrial (conference&journal)\\Sagittal Data Artical\\V0.47 Dataset analysis\\dataspitting\\Cropped_ROIs_V0.47_Split\\test_by_class\"\n",
    "\n",
    "# Path to your SAVED MODEL (from the previous training step)\n",
    "# Make sure this points to where you saved the .pth file\n",
    "model_path = r\"D:\\Submitted Matrial (conference&journal)\\Sagittal Data Artical\\V0.47 Dataset analysis\\dataspitting\\Cropped_ROIs_V0.47_Split\\train_by_class\\deit_balanced.pth\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on: {device}\")\n",
    "\n",
    "# ---------------------- 3. Transforms (Validation only) ----------------------\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# ---------------------- 4. Dataset Class (Test Mode) ----------------------\n",
    "class TestImageFolderDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.samples = []\n",
    "        # We explicitly define classes 0, 1, 2, 3 to match training\n",
    "        # This ensures that even if class \"3\" is missing in test, the order stays correct.\n",
    "        self.classes = ['0', '1', '2', '3'] \n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        print(f\"Class Mapping: {self.class_to_idx}\")\n",
    "        \n",
    "        for label_str in self.classes:\n",
    "            label_dir = os.path.join(root_dir, label_str)\n",
    "            if not os.path.exists(label_dir):\n",
    "                print(f\"Warning: Folder '{label_str}' not found in test path.\")\n",
    "                continue\n",
    "                \n",
    "            label = self.class_to_idx[label_str]\n",
    "            for fname in os.listdir(label_dir):\n",
    "                if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                    self.samples.append((os.path.join(label_dir, fname), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if img is None:\n",
    "            return np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8), label\n",
    "\n",
    "        img = cv2.equalizeHist(cv2.resize(img, (IMG_SIZE, IMG_SIZE)))\n",
    "        img = np.stack([img]*3, axis=-1)\n",
    "        \n",
    "        # Apply Transform\n",
    "        img = test_transform(image=img)['image']\n",
    "        return img, label\n",
    "\n",
    "# ---------------------- 5. Load Data ----------------------\n",
    "print(\"\\nLoading Test Data...\")\n",
    "test_ds = TestImageFolderDataset(test_dataset_root)\n",
    "\n",
    "# Create DataLoader\n",
    "test_dl = DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=0, # Critical for Windows\n",
    "    pin_memory=False\n",
    ")\n",
    "print(f\"Found {len(test_ds)} test images.\")\n",
    "\n",
    "# ---------------------- 6. Load Model ----------------------\n",
    "print(\"\\nLoading Model Architecture...\")\n",
    "model = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_patch16_224', pretrained=False)\n",
    "model.head = nn.Sequential(nn.Dropout(0.25), nn.Linear(192, NUM_CLASSES))\n",
    "\n",
    "print(f\"Loading Weights from: {model_path}\")\n",
    "# Load the weights we saved earlier\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.to(device)\n",
    "model.eval() # Set to evaluation mode\n",
    "\n",
    "# ---------------------- 7. Run Inference ----------------------\n",
    "print(\"\\nRunning Prediction...\")\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dl:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# ---------------------- 8. Calculate Metrics ----------------------\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"             TEST REPORT\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Total Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Detailed Report (Precision, Recall, F1 per class)\n",
    "report = classification_report(all_labels, all_preds, target_names=test_ds.classes)\n",
    "print(\"\\nDetailed Metrics:\")\n",
    "print(report)\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_ds.classes)\n",
    "disp.plot(cmap='Blues', values_format='d', ax=ax)\n",
    "plt.title(f\"Test Set Confusion Matrix\\nAccuracy: {acc:.2f}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
